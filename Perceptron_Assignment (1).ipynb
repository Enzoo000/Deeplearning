{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802da006",
   "metadata": {},
   "source": [
    "# **CSCE 5218 / CSCE 4930 Deep Learning**\n",
    "\n",
    "## **The Perceptron Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a941a8",
   "metadata": {},
   "source": [
    "## **Question 1**\n",
    "### Why don't we have the following code snippet instead?\n",
    "```python\n",
    "output = predict(weights, instance)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "### **Answer:**\n",
    "Using `predict(weights, instance)` directly returns a binary output (0 or 1) since it applies a threshold at 0.5, whereas `output = sigmoid(in_value)` provides a continuous value between 0 and 1. This is important for training since the perceptron uses gradient descent, which requires a differentiable function (the sigmoid function). If we used `predict`, the updates would be less precise, and learning would not be as smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c78e7",
   "metadata": {},
   "source": [
    "## **Question 2**\n",
    "### Training the Perceptron with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Read dataset\n",
    "def read_data(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data = []\n",
    "        f.readline()  # Skip header line\n",
    "        for instance in f.readlines():\n",
    "            if not re.search(r'\\t', instance):\n",
    "                continue\n",
    "            instance = list(map(int, instance.strip().split('\\t')))\n",
    "            instance = [-1] + instance  # Add bias term\n",
    "            data.append(instance)\n",
    "    return data\n",
    "\n",
    "# Perceptron helper functions\n",
    "def dot_product(array1, array2):\n",
    "    return sum(a * b for a, b in zip(array1, array2))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def output(weights, instance):\n",
    "    return sigmoid(dot_product(weights, instance))\n",
    "\n",
    "def predict(weights, instance):\n",
    "    return 1 if output(weights, instance) >= 0.5 else 0\n",
    "\n",
    "def get_accuracy(weights, instances):\n",
    "    correct = sum(1 if predict(weights, instance) == instance[-1] else 0 for instance in instances)\n",
    "    return correct * 100 / len(instances)\n",
    "\n",
    "def train_perceptron(instances, lr, epochs):\n",
    "    weights = [0] * (len(instances[0]) - 1)\n",
    "    for _ in range(epochs):\n",
    "        for instance in instances:\n",
    "            in_value = dot_product(weights, instance)\n",
    "            out = sigmoid(in_value)\n",
    "            error = instance[-1] - out\n",
    "            for i in range(len(weights)):\n",
    "                weights[i] += lr * error * out * (1 - out) * instance[i]\n",
    "    return weights\n",
    "\n",
    "# Load dataset\n",
    "train_data = read_data(\"train.txt\")\n",
    "test_data = read_data(\"test_small.txt\")\n",
    "\n",
    "# Hyperparameters\n",
    "tr_percent = [5, 10, 25, 50, 75, 100]\n",
    "num_epochs = [5, 10, 20, 50, 100]\n",
    "lr_values = [0.005, 0.01, 0.05]\n",
    "\n",
    "# Train perceptron and store results\n",
    "results = []\n",
    "for tr_p in tr_percent:\n",
    "    tr_size = int(len(train_data) * (tr_p / 100))\n",
    "    train_subset = train_data[:tr_size]\n",
    "    for epochs in num_epochs:\n",
    "        for lr in lr_values:\n",
    "            weights = train_perceptron(train_subset, lr, epochs)\n",
    "            accuracy = get_accuracy(weights, test_data)\n",
    "            results.append(f\"# tr: {tr_size}, epochs: {epochs}, learning rate: {lr:.3f}; Accuracy (test, {len(test_data)} instances): {accuracy:.1f}\")\n",
    "\n",
    "# Display results\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737ee9f",
   "metadata": {},
   "source": [
    "## **Question 3**\n",
    "### Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59777bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert results to DataFrame\n",
    "data = []\n",
    "for res in results:\n",
    "    parts = res.replace(\"# tr:\", \"\").replace(\"epochs:\", \"\").replace(\"learning rate:\", \"\").replace(\"Accuracy (test, 14 instances):\", \"\").split(\";\")\n",
    "    tr_size, epochs, lr, accuracy = map(str.strip, parts)\n",
    "    data.append([int(tr_size), int(epochs), float(lr), float(accuracy)])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Training Size\", \"Epochs\", \"Learning Rate\", \"Accuracy\"])\n",
    "\n",
    "# Plot accuracy trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "for lr in df[\"Learning Rate\"].unique():\n",
    "    subset = df[df[\"Learning Rate\"] == lr]\n",
    "    plt.plot(subset[\"Training Size\"], subset[\"Accuracy\"], marker=\"o\", linestyle=\"-\", label=f\"LR={lr}\")\n",
    "\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy vs. Training Size for Different Learning Rates\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233b2ef",
   "metadata": {},
   "source": [
    "### **Analysis and Answers**\n",
    "\n",
    "- **A. Do you need to train with all the training dataset to get the highest accuracy with the test dataset?**  \n",
    "  Not necessarily. In some cases, a subset of the data provides similar accuracy. Adding too much data may introduce noise.\n",
    "\n",
    "- **B. Why does training the second run obtain worse accuracy than the first one, even with more data?**  \n",
    "  This could be due to overfitting or suboptimal learning rates. More data does not always mean better generalization.\n",
    "\n",
    "- **C. Can you get higher accuracy with additional hyperparameters (higher than 80.0)?**  \n",
    "  Yes, adjusting learning rates or using different activation functions might improve performance.\n",
    "\n",
    "- **D. Is it always worth training for more epochs?**  \n",
    "  No. Sometimes more epochs lead to overfitting, decreasing generalization on test data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
